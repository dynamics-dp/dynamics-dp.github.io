<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title> Neural Dynamics Augmented Diffusion Policy </title>
	<link href="res/css/bootstrap.min.css" rel="stylesheet">
	<script src="res/css/fa.js"></script>

	<style>
      .header {
        width: auto;
        padding-top: 4rem;
        padding-bottom: 2rem;
      }

      a:link,a:visited
      {
        color: #0071bc;
        text-decoration: none;
      }

      a:hover {
        color: #208799;
      }

      .section-div {height: 3em}
      .content-div {height: 1em}

      .no-gutters {
	      margin-right: 0;
	      margin-left: 0;
      }

	  .btn {
	      margin-left: 0.2rem;
	  	  margin-right: 0.2rem;
	  }

	</style>
</head>

<div class="header">
	<center><h1>Neural Dynamics Augmented Diffusion Policy</h1></center>
	<div class="content-div"></div>
	<center>
		<a href="https://warshallrho.github.io/" target="_blank" style="font-size:18px">Ruihai Wu</a><sup style="font-size:12px">&nbsp*1</sup>,&nbsp
		<a href="dynamics-dp.github.io" target="_blank" style="font-size:18px">Haozhe Chen</a><sup style="font-size:12px">&nbsp*2</sup>,&nbsp
        <a href="https://robo-alex.github.io/" target="_blank" style="font-size:18px">Mingtong Zhang</a><sup style="font-size:12px">&nbsp*2</sup>,&nbsp
        <a href="dynamics-dp.github.io" target="_blank" style="font-size:18px">Haoran Lu</a><sup style="font-size:12px">&nbsp1</sup>,&nbsp
        <a href="dynamics-dp.github.io" target="_blank" style="font-size:18px">Yitong Li</a><sup style="font-size:12px">&nbsp1</sup>,&nbsp
		<a href="https://yunzhuli.github.io/" target="_blank" style="font-size:18px">Yunzhu Li</a><sup style="font-size:12px">&nbsp3</sup>
	</center>

	<center>
		<sup style="font-size:12px">&nbsp*</sup> Equal Contribution
	</center>

	<div class="content-div"></div>
	<center>
		<sup style="font-size:12px">1</sup>&nbspPeking University,
		<sup style="font-size:12px">2</sup>&nbspUniversity of Illinois Urbana-Champaign,
		<sup style="font-size:12px">3</sup>&nbspColumbia University
	</center>

	<div class="content-div"></div>
	<center>
		<div class="btn-group" role="group">

			<a href="dynamics-dp.github.io" target="_blank">
				<button type="button" class="btn btn-dark"><span class="icon">
					<i class="fas fa-file-pdf"></i> Paper
				</span></button>
			</a>

			<a href="dynamics-dp.github.io" target="_blank">
				<button type="button" class="btn btn-dark"><span class="icon">
					<i class="fab fa-github"></i> Code
				</span></button>
			</a>

<!--			<a href="">-->
<!--				<button type="button" class="btn btn-dark"><span class="icon">-->
<!--					<i class="fab fa-youtube"></i> Video-->
<!--				</span></button>-->
<!--			</a>-->

			<!-- <a href="dynamics-dp.github.io">
				<button type="button" class="btn btn-dark"><span class="icon">
					<i class="fab fa-twitter"></i> Twitter
				</span></button>
        	</a> -->

		</div>
	</center>
</div>

<div class="container">
	<!--------------------- abstract --------------------->
	<center>
		<h2> Abstract </h2>
		<div class="content-div"></div>
		<p style="width:75%; text-align: justify; white-space: normal;"> Imitation learning has been proven effective in mimicking demonstrations across various robotic manipulation tasks. 
            However, to develop robust policies, current imitation methods, such as diffusion policy, require training on extensive demonstrations, making data collection labor-intensive.
            In contrast,
            model-based planning with dynamics models can effectively cover a sufficient range of configurations using only off-policy data.
            Yet, without the guidance of expert demonstrations, many tasks are difficult and time-consuming to plan using the dynamics models.
            Therefore, we take the best of both dynamics model and imitation learning, and propose neural dynamics augmented imitation learning that covers a large scene configurations with few-shot demonstrations.
            This method trains a robust diffusion policy in a local support region with few-shot demonstrations, and manipulates the randomly initialized object to this region with neural dynamics models trained offline.
            Extensive experiments across various tasks in both simulations and real-world scenarios, 
            including granular manipulation, contact-rich task and multi-object interaction task, 
            have demonstrated that trained with only 1 to 30 demonstrations, our proposed method can robustly cover a significantly larger area than the policy trained purely from the demonstrations. </p>
	</center>


	<div class="content-div"></div>
	<div class="col">
		<center><video playsinline autoplay loop muted controls src="videos/teaser.mp4" width="100%" preload="metadata"
			   style="border-radius:10px;"></video>
		</center>
	</div>

	<div class="content-div"></div>

	<center>
		<h2> Overview </h2>
	</center>
	<div class="content-div"></div>
	<div class="col">
		<center><img class="img-fluid" src="res/teaser.png" style="margin-bottom: 30px" width="100%" alt=""><br>
			<p style="width:75%; text-align: justify; white-space: normal;">
				<strong>(Left)</strong> We propose neural dynamics augmented diffusion policy, with few-shot diffusion policy robustly covering a local supporting region and a dynamics model extending the initial configuration space. The 
				<span style="color: rgb(102, 204, 102); font-weight: bold;">green</span> 
				region denotes the supporting region that few-shot diffusion policy covers, and the 
				<span style="color: rgb(252, 153, 153); font-weight: bold;">red</span> 
				region denotes the space out of the supporting region where model-based planning with the dynamics model can cover.
				<strong>(Right)</strong> The proposed method has demonstrated its performance in various tasks. The 
				<span style="color: rgb(77, 153, 77); font-weight: bold;">deep green</span> 
				region denotes the area few-shot diffusion policy can cover, and the 
				<span style="color: rgb(102, 204, 102); font-weight: bold;">light green</span> 
				region denotes our method's augmentation on the space.
			 </p>
		</center>
	</div>


	<center>
		<div class="section-div"></div>
		<h2> Method </h2>
		<div class="content-div"></div>
		<img class="img-fluid" src="res/method.png" style="margin-bottom: 30px" width="100%" alt=""><br>
		<p style="width:75%; text-align: justify; white-space: normal;"> <b>Our Proposed Framework.</b> (a) Collecting few-shot human demonstrations that could cover a convex hull in the space. (b) Diffusion policy trained on the few-shot human demonstrations is robust in the local supporting region, but lacks robustness in outside configurations. (c) Model-based planning equipped with dynamics models generates manipulation trajectories from various initial poses to the supporting region. (d) The whole policy leveraging trajectories generated in (c) is robust in the large space. </p>
	</center>


	<div class="section-div"></div>
	<center>
		<h2> Real-World Results of InsertT</h2>
	</center>

	<div class="content-div"></div>
	<div class="row align-items-start"> <!-- First Row of Videos -->
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/T_05_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/T_06_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
	</div>
	
	<div class="content-div"></div>
	<div class="row align-items-start"> <!-- Second Row of Videos -->
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/T_07_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/T_08_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
	</div>
	
	<div class="content-div"></div>
	<div class="row align-items-start"> <!-- Third Row of Videos -->
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/T_09_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/T_10_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
	</div>


	<div class="content-div"></div>
	<div class="row align-items-start"> <!-- Third Row of Videos -->
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/T_11_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/T_12_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<center>
			<p style="width:75%; text-align: center; white-space: normal;"> 
				<b>InsertT: </b> inserting a T-Shape (initially put on a random position with a random orientation on the table) into a slot. The manipulation succeeds when the T is successfully inserted into the slot. </p>
		</center>
	</div>

	<center>
		<h2 style="margin-top: 40px;">Real-World Results of Stow</h2>
	</center>
	<div class="content-div"></div>
	<div class="row align-items-start"> <!-- Third Row of Videos -->
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/stow_00_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/stow_01_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
	</div>

	<div class="content-div"></div>
	<div class="row align-items-start"> <!-- Third Row of Videos -->
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/stow_02_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/stow_03_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<center>
			<p style="width:75%; text-align: center; white-space: normal;"> 
				<b>Stow: </b> stowing a book (initially put on a random position with a random orientation on the table) onto the bookshelf with a few books. The manipulation succeeds when all books are placed in upright posture. </p>
		</center>
	</div>

	<center>
		<h2 style="margin-top: 40px;">Real-World Results of DustPan</h2>
	</center>
	<div class="content-div"></div>
	<div class="row align-items-start"> <!-- Third Row of Videos -->
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/dustpan_00_16x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/dustpan_01_16x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
	</div>

	<div class="content-div"></div>
	<div class="row align-items-start"> <!-- Third Row of Videos -->
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/dustpan_02_16x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/dustpan_03_16x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<center>
			<p style="width:75%; text-align: center; white-space: normal;"> 
				<b>DustPan: </b> sweeping sparsely located granular into the dustpan. The evaluation metric in simulation is defined by the ratio of granular successfully swept into the dustpan, with success in the real world determined by sweeping a certain percentage 90% of pieces into the dustpan. </p>
		</center>
	</div>


	<center>
		<h2 style="margin-top: 40px;">Real-World Results of HangMug</h2>
	</center>
	<div class="content-div"></div>
	<div class="row align-items-start"> <!-- Third Row of Videos -->
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/mug_00_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/mug_01_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
	</div>

	<div class="content-div"></div>
	<div class="row align-items-start"> <!-- Third Row of Videos -->
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/mug_02_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<div class="col-md-6 d-flex flex-column align-items-center">
			<div class="content-div"></div>
			<video playsinline autoplay loop muted src="videos/mug_03_x.mp4" width="99%" style="border-radius:10px;"></video>
		</div>
		<center>
			<p style="width:75%; text-align: center; white-space: normal;"> 
				<b>HangMug: </b> hanging a mug (randomly positioned on the table) on the rack. The manipulation succeeds when the mug is successfully hung on the rack. </p>
		</center>
	</div>

	<div class="content-div"></div>
	<div class="row align-items-start"> <!-- Third Row of Videos -->
		<p style="width:100%; text-align: center; white-space: normal;"> 
		</p>
	</div>



	
	
	
	
	<!-- <div class="row align-items-center">
		<div class="col-md-6 align-column-center">
			<center>
			</center>
			<div class="content-div"></div>
			<center>
				<video playsinline autoplay loop muted src="videos/cube_color.mp4" width="99%" style="border-radius:10px;"></video>
				<p style="width:85%; text-align: center; white-space: normal;"> 
					Divide the cubes of different colors into two pieces. 
				</p>				
			</center>
		</div>
		<div class="col-md-6 align-column-center">
			<center>
				<div class="content-div"></div>
				<video playsinline autoplay loop muted src="videos/cube_color_02.mp4" width="99%" style="border-radius:10px;"></video>
				<p style="width:85%; text-align: center; white-space: normal;"> 
					Move the yellow cubes to the red cross and the green cubes to the blue cross.
				</p>
			</center>
		</div>
	</div> -->


	<center>
		<h2> Analysis</h2>
	</center>

	<div class="content-div"></div>
	<div class="col">
		<center><img class="img-fluid" src="res/experiment_result_insertT.png" style="margin-bottom: 30px" width="100%" alt=""><br>
			<p style="width:75%; text-align: justify; white-space: normal;"> <b>Qualitative Analysis on InsertT.</b> With the same few-shot human demonstrations, while the original diffusion policy demonstrates robustness only in a certain local region, our proposed method supports the policy robustness in a much wider space with the augmentation of the neural dynamics model. The demonstrations in <b>Diffusion Policy</b> show the few-shot (10) human demonstrations, and those in \textbf{Ours} show dynamics augmented demonstrations cover the large space. </p>
		</center>
	</div>

	<div class="content-div"></div>
	<div class="col">
		<center><img class="img-fluid" src="res/experiment_result_3in1.png" style="margin-bottom: 30px" width="100%" alt=""><br>
			<p style="width:75%; text-align: justify; white-space: normal;"> <b>Qualitative Analysis on DustPan, Stow and HangMug.</b>     While diffusion policy only covers specific regions, our method covers a significantly larger space with model-based planning to manipulate diverse objects among different tasks into the local supporting region, followed by the few-shot diffusion policy. 
				For <strong>DustPan</strong>, "Planning" denotes this step is fulfilled by model-based planning.
				For <strong>HangMug</strong>, 
				<span style="color: green; font-weight: bold;">green</span> 
				denotes success and 
				<span style="color: rgb(252, 153, 153); font-weight: bold;">red</span> 
				denotes failure. </p>
		</center>
	</div>

	<!--------------------- Bibtex --------------------->
	<!-- <div class="content-div"></div>
	<center><h2> Bibtex </h2></center>
	<div class="content-div"></div>
	<pre>
	  @article{liu2024kuda,
	     author={Liu, Zixian and Zhang, Mingtong and Li, Yunzhu},
	     title={KUDA: Keypoints to Unify Dynamics Learning and Visual Prompting for Open-Vocabulary Robotic Manipulation},
	     journal={arXiv},
	     year={2024}
	   }

	</pre> -->


	<div class="section-div"></div>

	<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
	<!-- Include all compiled plugins (below), or include individual files as needed -->
	<script src="res/js/bootstrap.min.js"></script>
</div>

</html>